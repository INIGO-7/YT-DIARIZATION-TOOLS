{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path = \"diarized_audio/raw_diarizations\"\n",
    "diarization_paths = {}\n",
    "for directory in os.listdir(d_path):\n",
    "    diarization_paths[directory] = os.path.join(d_path, directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Careful!` -- the following cell deletes previous work. If intended, run to make way for the new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove all csv files from diarization directory\n",
    "for path in os.listdir(d_path):\n",
    "    !rm -r {os.path.join(d_path, path)}/speaker_turns.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_directories(arr):\n",
    "    def sort_key(s):\n",
    "        return int(s.split('_')[1])\n",
    "\n",
    "    return sorted(arr, key=sort_key)\n",
    "\n",
    "def parse_time(time_str):\n",
    "    # Parses the time string to a pandas.Timedelta object\n",
    "    return pd.Timedelta(time_str)\n",
    "\n",
    "def process_line(line):\n",
    "    # Splits the line and extracts the required information\n",
    "    time_data, speaker = line.split(']')\n",
    "    time_data = time_data[2:]\n",
    "    start_time, end_time = time_data.split(' -->  ')\n",
    "    speaker = speaker.split(' ')[-1]  # Gets only the SPEAKER_xx part\n",
    "    return speaker, parse_time(start_time), parse_time(end_time)\n",
    "\n",
    "def most_common_letters(string, dictionary):\n",
    "    def common_letter_count(s1, s2):\n",
    "        return sum(min(s1.count(c), s2.count(c)) for c in set(s1))\n",
    "\n",
    "    max_key = max(dictionary.keys(), key=lambda k: common_letter_count(k.lower(), string.lower()))\n",
    "    return dictionary[max_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker_turns(podcast_dictionaries, verbose : bool = False):\n",
    "    diarizations = \"diarized_audio/raw_diarizations\"\n",
    "    directories = [\n",
    "        directory \n",
    "        for directory in os.listdir(diarizations) \n",
    "        if directory in podcast_dictionaries.keys()\n",
    "    ]\n",
    "    \n",
    "    for podcast_name in directories:\n",
    "\n",
    "        directory = os.path.join(diarizations, podcast_name)\n",
    "        podcast_df = pd.DataFrame(columns=['speaker', 'start', 'end'])\n",
    "        spacer_time = pd.Timedelta('0 days 00:00:00.998000')\n",
    "        global_time = pd.Timedelta('0')\n",
    "        splits = sort_directories([d for d in os.listdir(directory) if d.endswith('.txt')])\n",
    "        #to_replace_dict = most_common_letters(podcast_name, podcast_dictionaries)\n",
    "        to_replace_dict = podcast_dictionaries[podcast_name]\n",
    "        \n",
    "        if verbose: \n",
    "            print(directory)\n",
    "            print(to_replace_dict)\n",
    "        \n",
    "        for idx, split in enumerate(splits):\n",
    "            \n",
    "            file_path = os.path.join(directory, split)\n",
    "            # get split number with regex that searches for a number\n",
    "            number = re.search(r'\\d+(\\.\\d+)?', split).group()\n",
    "            # get the speakers (SPEAKER_00, SPEAKER_...) that talk in this split\n",
    "\n",
    "            # In case we want to discard the data in one of the splits, just go to the next split.\n",
    "            if to_replace_dict[number] == \"\":\n",
    "                continue\n",
    "\n",
    "            real_speakers = to_replace_dict[number].split(\";\")\n",
    "\n",
    "            with open(file_path, 'r') as file:\n",
    "                for line in file:\n",
    "                    speaker, start, end = process_line(line)\n",
    "\n",
    "                    # Set the correct speaker\n",
    "\n",
    "                    speaker = speaker.strip('\\n')\n",
    "                    for rsp in real_speakers:\n",
    "                        rsp = rsp.split(\",\")\n",
    "                        pyannote_speaker = 'SPEAKER_' + rsp[0]\n",
    "                        \n",
    "                        if pyannote_speaker == speaker:\n",
    "                            speaker = rsp[1]\n",
    "                    \n",
    "                    # Adjust start and end to the global time\n",
    "                    start = start + global_time - spacer_time\n",
    "                    end = end + global_time - spacer_time\n",
    "\n",
    "                    #Create a new tagged speaker intervention in the podcast\n",
    "                    podcast_df.loc[len(podcast_df)] = [speaker, start, end]\n",
    "            \n",
    "            global_time = podcast_df[\"end\"].max()\n",
    "    \n",
    "        pattern = 'SPEAKER_\\d+'\n",
    "        filtered_df = podcast_df[~podcast_df['speaker'].str.contains(pattern, na=False)]\n",
    "        filtered_df.to_csv(os.path.join(directory, \"speaker_turns.csv\"), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speakers import replacer_dict\n",
    "\n",
    "get_speaker_turns(replacer_dict, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we get what a speaker has said in text, linking the diarizations with the transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to find the closest time in df2 to a given time in df1\n",
    "def find_closest_start_time(df, given_time):\n",
    "    # Calculate absolute time differences\n",
    "    \n",
    "    time_diff = (df['start'] - given_time).abs()\n",
    "    \n",
    "    # Find the index of the minimum difference\n",
    "    closest_index = time_diff.idxmin()\n",
    "    return closest_index\n",
    "\n",
    "def find_closest_end_time(df, given_time):\n",
    "    # Calculate absolute time differences\n",
    "    \n",
    "    time_diff = (df['end'] - given_time).abs()\n",
    "    \n",
    "    # Find the index of the minimum difference\n",
    "    closest_index = time_diff.idxmin()\n",
    "    return closest_index\n",
    "\n",
    "def add_text_to_diarization(diarization_df, transcriptions_df):\n",
    "\n",
    "    # New column for the combined text\n",
    "    diarization_df['text'] = ''\n",
    "\n",
    "    for index, row in diarization_df.iterrows():\n",
    "        # Find closest start and end times in df2\n",
    "        \n",
    "        closest_start_index = find_closest_start_time(transcriptions_df, row['start'])\n",
    "        closest_end_index = find_closest_end_time(transcriptions_df, row['end'])\n",
    "\n",
    "        # Extract all rows in-between these indices\n",
    "        if closest_start_index <= closest_end_index:\n",
    "            relevant_text = transcriptions_df.loc[closest_start_index:closest_end_index, 'text']\n",
    "        else:\n",
    "            relevant_text = transcriptions_df.loc[closest_end_index:closest_start_index, 'text']\n",
    "\n",
    "        # Combine the text and add to dataframe\n",
    "        combined_text = \"\".join(relevant_text)\n",
    "        diarization_df.at[index, 'text'] = combined_text\n",
    "\n",
    "    # dataframe now contains the combined text in the new 'text' column\n",
    "    return diarization_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all podcasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get speaker-tagged transcriptions for each dataframe, and save them in the datasets directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diarizations = \"diarized_audio/raw_diarizations\"\n",
    "\n",
    "directories = [\n",
    "    directory\n",
    "    for directory in os.listdir(diarizations) \n",
    "    if \"speaker_turns.csv\" in os.listdir(os.path.join(diarizations, directory))\n",
    "]\n",
    "\n",
    "for podcast_name in directories:\n",
    "    directory = os.path.join(diarizations, podcast_name)\n",
    "\n",
    "    diarization = pd.read_csv(f\"diarized_audio/raw_diarizations/{podcast_name}/speaker_turns.csv\")\n",
    "    transcription = pd.read_csv(f\"transcribed_audio/{podcast_name}_transcribed.csv\")\n",
    "\n",
    "    # Do a bit of data cleaning\n",
    "    transcription['start'] = pd.to_timedelta(transcription['start'], unit='s')\n",
    "    transcription['end'] = pd.to_timedelta(transcription['end'], unit='s')\n",
    "\n",
    "    diarization['start'] = pd.to_timedelta(diarization['start'])\n",
    "    diarization['end'] = pd.to_timedelta(diarization['end'])\n",
    "\n",
    "    all_transcriptions = \"\".join(transcription[\"text\"])\n",
    "\n",
    "    final_df = add_text_to_diarization(diarization, transcription)\n",
    "    final_df.to_csv(os.path.join(\"datasets\", podcast_name + \".csv\"), header=True, index=False)\n",
    "\n",
    "    # speaked = final_df.groupby(\"speaker\")['text'].apply(lambda x: ''.join(x))\n",
    "    # print(\"Number of words:\", len(tweet_tokenizer.tokenize(all_transcriptions)))\n",
    "    # print(\"Number of sentences:\", len(sent_tokenize(all_transcriptions)))\n",
    "    # print(speaked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then join them all in a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = \"diarized_transcribed_df\"\n",
    "podcast_arr = []\n",
    "\n",
    "for podcast_name in directories:\n",
    "    podcast = pd.read_csv(os.path.join('datasets', podcast_name + '.csv'))\n",
    "    podcast_arr.append(podcast)\n",
    "\n",
    "diarized_transcribed_df = pd.concat(podcast_arr)\n",
    "diarized_transcribed_df.to_csv(os.path.join(\"datasets\", df_name + '.csv'), header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare podcasts for the neural network & prediction making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = diarized_transcribed_df[['speaker', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_and_split_dataframe(df, class_column, split_prob=[0.7, 0.15, 0.15]):\n",
    "\n",
    "    #split parameters\n",
    "    choices = ['train', 'test', 'val']\n",
    "\n",
    "    # Group by class and find the smallest class size\n",
    "    group = df.groupby(class_column)\n",
    "    smallest_class_size = group.size().min()\n",
    "\n",
    "    # Sample from each class (we can use with multi-label)\n",
    "    undersampled_df = pd.DataFrame()\n",
    "    for _, group_df in group:\n",
    "        sampled_df = group_df.sample(n=smallest_class_size, replace=False, random_state=1)\n",
    "\n",
    "        # Perform the split class by class, for the train, test and validation rows to be balanced.\n",
    "        sampled_df['split'] = np.random.choice(choices, size=len(sampled_df), p=split_prob)\n",
    "        undersampled_df = pd.concat([undersampled_df, sampled_df], axis=0)\n",
    "\n",
    "    # Check the distribution\n",
    "    print(undersampled_df['split'].value_counts(normalize=True))\n",
    "\n",
    "    return undersampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df = undersample_and_split_dataframe(df, 'speaker')\n",
    "prepared_df.columns = ['category', 'title', 'split']\n",
    "prepared_df = prepared_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df.groupby('category').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df.to_csv(os.path.join(\"datasets\", df_name + \"_preparado.csv\"), header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YTANDWHISPER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
