{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path = \"diarized_audio/raw_diarizations\"\n",
    "diarization_paths = {}\n",
    "for directory in os.listdir(d_path):\n",
    "    diarization_paths[directory] = os.path.join(d_path, directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, process all the files to have a suitable format. This will be a pandas dataframe, stored in memory as a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all csv files from diarization directory\n",
    "# for path in os.listdir(d_path):\n",
    "#     !rm -r {os.path.join(d_path, path)}/speaker_turns.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_replace_dict = {\n",
    "#     \"1\":\"01,HUBERMAN;00,ANDREW\",\n",
    "#     \"2\":\"00,HUBERMAN;01,ANDREW\",\n",
    "#     \"3\":\"01,HUBERMAN;00,ANDREW\",\n",
    "#     \"4\":\"00,HUBERMAN;01,ANDREW\",\n",
    "#     \"5\":\"02,HUBERMAN;01,ANDREW\",\n",
    "#     \"6\":\"01,HUBERMAN;00,ANDREW\",\n",
    "#     \"7\":\"01,HUBERMAN\",\n",
    "#     \"8\":\"01,HUBERMAN;02,ANDREW\",\n",
    "#     \"9\":\"01,HUBERMAN;00,ANDREW\",\n",
    "#     \"10\":\"02,HUBERMAN;03,ANDREW\",\n",
    "#     \"11\":\"02,HUBERMAN;01,ANDREW\",\n",
    "#     \"12\":\"00,HUBERMAN\",\n",
    "#     \"13\":\"00,HUBERMAN;01,ANDREW\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_directories(arr):\n",
    "    def sort_key(s):\n",
    "        return int(s.split('_')[1])\n",
    "\n",
    "    return sorted(arr, key=sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(time_str):\n",
    "    # Parses the time string to a pandas.Timedelta object\n",
    "    return pd.Timedelta(time_str)\n",
    "\n",
    "def process_line(line):\n",
    "    # Splits the line and extracts the required information\n",
    "    time_data, speaker = line.split(']')\n",
    "    time_data = time_data[2:]\n",
    "    start_time, end_time = time_data.split(' -->  ')\n",
    "    speaker = speaker.split(' ')[-1]  # Gets only the SPEAKER_xx part\n",
    "    return speaker, parse_time(start_time), parse_time(end_time)\n",
    "\n",
    "def process_joerogan_kevinhart(to_replace_dict):\n",
    "    directory = \"diarized_audio/raw_diarizations/JRE-kevinHart-25052020\"\n",
    "\n",
    "    podcast_df = pd.DataFrame(columns=['speaker', 'start', 'end'])\n",
    "    spacer_time = pd.Timedelta('0 days 00:00:00.998000')\n",
    "    global_time = pd.Timedelta('0')\n",
    "    splits = sort_directories(os.listdir(directory))\n",
    "\n",
    "    for idx, split in enumerate(splits):\n",
    "        \n",
    "        file_path = os.path.join(directory, split)\n",
    "        # get split number with regex that searches for a number\n",
    "        number = re.search(r'\\d+(\\.\\d+)?', split).group()\n",
    "        # get the speakers (SPEAKER_00, SPEAKER_...) that talk in this split\n",
    "        #talkers = [\"SPEAKER_\" + n for n in re.split(\"[,;]\", to_replace_dict[number])[0::2]]\n",
    "        \n",
    "        if to_replace_dict[number] == \"\":   #TODO hay que utilizarlo pero no aquí\n",
    "            continue\n",
    "\n",
    "        real_speakers = to_replace_dict[number].split(\";\")\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                speaker, start, end = process_line(line)\n",
    "\n",
    "                # Set the correct speaker\n",
    "                speaker = speaker.strip('\\n')\n",
    "\n",
    "                for rsp in real_speakers:\n",
    "                    rsp = rsp.split(\",\")\n",
    "                    pyannote_speaker = 'SPEAKER_' + rsp[0]\n",
    "                    \n",
    "                    if pyannote_speaker == speaker:\n",
    "                        speaker = rsp[1]\n",
    "                \n",
    "                # Adjust start and end to the global time\n",
    "                start = start + global_time - spacer_time\n",
    "                end = end + global_time - spacer_time\n",
    "                podcast_df.loc[len(podcast_df)] = [speaker, start, end]\n",
    "        \n",
    "        global_time = podcast_df[\"end\"].max()\n",
    "    \n",
    "    podcast_df.to_csv(os.path.join(directory, \"speaker_turns.csv\"), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format will be split_number:speakers_with_replacement, where speakers\n",
    "# with replacement is a string with the number of speaker to replace and\n",
    "# the name, separated by a comma and separated by semicolon from other\n",
    "# speakers\n",
    "to_replace_dict = {\n",
    "    \"1\": \"00,KEVINHART;01,JOEROGAN\",\n",
    "    \"2\": \"00,KEVINHART;01,JOEROGAN\",\n",
    "    \"3\": \"00,KEVINHART;01,JOEROGAN\",\n",
    "    \"4\": \"00,JOEROGAN;01,KEVINHART\",\n",
    "    \"5\": \"00,JOEROGAN;01,KEVINHART\",\n",
    "    \"6\": \"00,KEVINHART;01,JOEROGAN\",\n",
    "    \"7\": \"00,KEVINHART;01,JOEROGAN\",\n",
    "    \"8\": \"00,KEVINHART;01,JOEROGAN\",\n",
    "    \"9\": \"01,KEVINHART;02,JOEROGAN\",\n",
    "    \"10\": \"00,KEVINHART;01,JOEROGAN\",\n",
    "    \"11\": \"00,KEVINHART;01,JOEROGAN\",\n",
    "    \"12\": \"00,KEVINHART;01,JOEROGAN\"\n",
    "}\n",
    "\n",
    "# dejar value de key vacío para indicar que no queremos coger de ese split\n",
    "\n",
    "process_joerogan_kevinhart(to_replace_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we get what a speaker has said in text, linking the diarizations with the transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization = pd.read_csv(\"diarized_audio/raw_diarizations/JRE-kevinHart-25052020/speaker_turns.csv\")\n",
    "transcription = pd.read_csv(\"transcribed_audio/JRE-kevinHart-25052020_transcribed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription['start'] = pd.to_timedelta(transcription['start'], unit='s')\n",
    "transcription['end'] = pd.to_timedelta(transcription['end'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization['start'] = pd.to_timedelta(diarization['start'])\n",
    "diarization['end'] = pd.to_timedelta(diarization['end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "all_transcriptions = \"\".join(transcription[\"text\"])\n",
    "print(\"Number of words:\", len(tweet_tokenizer.tokenize(all_transcriptions)))\n",
    "print(\"Number of sentences:\", len(sent_tokenize(all_transcriptions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a new column should be added to the diarization dataframe. This column will be the text said in that time frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to find the closest time in df2 to a given time in df1\n",
    "def find_closest_start_time(df, given_time):\n",
    "    # Calculate absolute time differences\n",
    "    \n",
    "    time_diff = (df['start'] - given_time).abs()\n",
    "    \n",
    "    # Find the index of the minimum difference\n",
    "    closest_index = time_diff.idxmin()\n",
    "    return closest_index\n",
    "\n",
    "def find_closest_end_time(df, given_time):\n",
    "    # Calculate absolute time differences\n",
    "    \n",
    "    time_diff = (df['end'] - given_time).abs()\n",
    "    \n",
    "    # Find the index of the minimum difference\n",
    "    closest_index = time_diff.idxmin()\n",
    "    return closest_index\n",
    "\n",
    "# New column for the combined text\n",
    "diarization['text'] = ''\n",
    "\n",
    "for index, row in diarization.iterrows():\n",
    "    # Find closest start and end times in df2\n",
    "    \n",
    "    closest_start_index = find_closest_start_time(transcription, row['start'])\n",
    "    closest_end_index = find_closest_end_time(transcription, row['end'])\n",
    "\n",
    "    # Extract all rows in-between these indices\n",
    "    if closest_start_index <= closest_end_index:\n",
    "        relevant_text = transcription.loc[closest_start_index:closest_end_index, 'text']\n",
    "    else:\n",
    "        relevant_text = transcription.loc[closest_end_index:closest_start_index, 'text']\n",
    "\n",
    "    # Combine the text and add to df1\n",
    "    combined_text = \"\".join(relevant_text)\n",
    "    diarization.at[index, 'text'] = combined_text\n",
    "\n",
    "# df1 now contains the combined text in the new 'text' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaked = diarization.groupby(\"speaker\")['text'].apply(lambda x: ''.join(x))\n",
    "speaked"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YTANDWHISPER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
